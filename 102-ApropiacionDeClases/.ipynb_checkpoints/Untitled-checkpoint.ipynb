{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c48ffc-9824-405e-b1a8-7d9bddf9b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Configuración Inicial y Carga de Librerías ---\n",
    "import torch\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration, pipeline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import gradio as gr\n",
    "import requests\n",
    "import fitz # PyMuPDF for PDF handling\n",
    "from pdf2image import convert_from_path # For converting PDF pages to images\n",
    "\n",
    "# --- 0.1 Configuración de PaliGemma ---\n",
    "PALI_GEMMA_MODEL_ID = \"google/paligemma-3b-mix-224\" # O \"google/paligemma-10b-mix-448\" si tienes más VRAM\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Cargar el procesador y el modelo PaliGemma UNA SOLA VEZ\n",
    "print(f\"Cargando modelo PaliGemma: {PALI_GEMMA_MODEL_ID} en {DEVICE} con dtype {DTYPE}...\")\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(PALI_GEMMA_MODEL_ID)\n",
    "    pali_gemma_model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        PALI_GEMMA_MODEL_ID,\n",
    "        torch_dtype=DTYPE,\n",
    "        device_map=DEVICE,\n",
    "        # load_in_8bit=True # Descomentar si tienes problemas de VRAM en T4\n",
    "    ).eval()\n",
    "    print(\"Modelo PaliGemma cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el modelo PaliGemma: {e}\")\n",
    "    print(\"Asegúrate de haber aceptado los términos en Hugging Face y de tener suficiente VRAM.\")\n",
    "    # Considera salir o manejar el error de forma más robusta en un entorno de producción\n",
    "    pali_gemma_model = None\n",
    "    processor = None\n",
    "\n",
    "# --- 0.2 Configuración del Modelo de Traducción ---\n",
    "# Usaremos un modelo de Transformers para traducción\n",
    "# \"Helsinki-NLP/opus-mt-en-es\" para Inglés a Español\n",
    "# \"Helsinki-NLP/opus-mt-es-en\" para Español a Inglés\n",
    "print(\"Cargando modelos de traducción...\")\n",
    "try:\n",
    "    translator_en_es = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\", device=0 if DEVICE == \"cuda\" else -1)\n",
    "    translator_es_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\", device=0 if DEVICE == \"cuda\" else -1)\n",
    "    print(\"Modelos de traducción cargados exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar modelos de traducción: {e}\")\n",
    "    translator_en_es = None\n",
    "    translator_es_en = None\n",
    "\n",
    "# --- Variables Globales para la Sesión ---\n",
    "current_image = None # Almacenará la imagen PIL cargada por el usuario\n",
    "indexed_text_content = \"\" # Almacenará el texto extraído de la imagen (OCR)\n",
    "\n",
    "# --- 0.3 Funciones Auxiliares ---\n",
    "\n",
    "def generate_paligemma_response(pil_image, prompt, max_new_tokens=500):\n",
    "    \"\"\"Genera una respuesta de texto de PaliGemma.\"\"\"\n",
    "    if pali_gemma_model is None or processor is None:\n",
    "        return \"Error: Modelo PaliGemma no cargado.\"\n",
    "    try:\n",
    "        inputs = processor(text=prompt, images=pil_image, return_tensors=\"pt\").to(DEVICE, DTYPE)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = pali_gemma_model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        response_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        response_text = response_text.replace(prompt, \"\").strip() # Limpia el prompt de la respuesta\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        return f\"Error al procesar la imagen con PaliGemma: {e}. Intenta con una imagen más pequeña o un prompt diferente.\"\n",
    "\n",
    "def perform_ocr_with_paligemma(pil_image):\n",
    "    \"\"\"Realiza OCR/Transcripción usando PaliGemma.\"\"\"\n",
    "    prompt = \"Transcribe todo el texto presente en esta imagen.\"\n",
    "    return generate_paligemma_response(pil_image, prompt, max_new_tokens=1500) # Más tokens para transcripción\n",
    "\n",
    "def explain_image_content(pil_image):\n",
    "    \"\"\"Pide a PaliGemma que explique el contenido de la imagen.\"\"\"\n",
    "    prompt = \"Describe detalladamente lo que se ve en esta imagen, centrándote en el contenido educativo o informativo.\"\n",
    "    return generate_paligemma_response(pil_image, prompt, max_new_tokens=1000)\n",
    "\n",
    "def translate_text(text_to_translate, source_lang, target_lang):\n",
    "    \"\"\"Traduce texto usando modelos Hugging Face.\"\"\"\n",
    "    if not text_to_translate:\n",
    "        return \"No hay texto para traducir.\"\n",
    "    if source_lang == target_lang:\n",
    "        return text_to_translate\n",
    "\n",
    "    try:\n",
    "        if source_lang == \"en\" and target_lang == \"es\" and translator_en_es:\n",
    "            res = translator_en_es(text_to_translate)\n",
    "            return res[0]['translation_text']\n",
    "        elif source_lang == \"es\" and target_lang == \"en\" and translator_es_en:\n",
    "            res = translator_es_en(text_to_translate)\n",
    "            return res[0]['translation_text']\n",
    "        else:\n",
    "            return \"Modelos de traducción no disponibles para la dirección seleccionada o no cargados.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error durante la traducción: {e}\"\n",
    "\n",
    "# --- Funciones de la Interfaz Gradio ---\n",
    "\n",
    "def index_data(file):\n",
    "    \"\"\"\n",
    "    Simula la carga y extracción de contenido de una imagen o PDF.\n",
    "    Esta función se llama cuando el usuario sube un archivo.\n",
    "    \"\"\"\n",
    "    global current_image\n",
    "    global indexed_text_content\n",
    "\n",
    "    indexed_text_content = \"\" # Resetear contenido indexado\n",
    "    current_image = None\n",
    "\n",
    "    if file is None:\n",
    "        return \"Por favor, sube un archivo.\", None, \"\", \"\"\n",
    "\n",
    "    file_path = file.name # Gradio pasa el objeto archivo, su path está en .name\n",
    "\n",
    "    if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        print(f\"Procesando imagen: {file_path}\")\n",
    "        pil_image = Image.open(file_path).convert(\"RGB\")\n",
    "        current_image = pil_image\n",
    "        status_message = \"Imagen cargada. Puedes hacer preguntas o transcribir.\"\n",
    "\n",
    "    elif file_path.lower().endswith('.pdf'):\n",
    "        print(f\"Procesando PDF: {file_path}\")\n",
    "        try:\n",
    "            # Convertir la primera página del PDF a imagen. Podrías iterar si quieres todo el PDF.\n",
    "            images = convert_from_path(file_path, first_page=1, last_page=1)\n",
    "            if images:\n",
    "                pil_image = images[0].convert(\"RGB\")\n",
    "                current_image = pil_image\n",
    "                status_message = \"PDF (primera página) cargado como imagen. Puedes hacer preguntas o transcribir.\"\n",
    "            else:\n",
    "                status_message = \"No se pudieron extraer imágenes del PDF.\"\n",
    "                return status_message, None, \"\", \"\"\n",
    "        except Exception as e:\n",
    "            status_message = f\"Error al procesar el PDF: {e}. Asegúrate de que 'poppler-utils' esté instalado.\"\n",
    "            return status_message, None, \"\", \"\"\n",
    "    else:\n",
    "        status_message = \"Formato de archivo no soportado. Por favor, sube una imagen (JPG, PNG) o PDF.\"\n",
    "        return status_message, None, \"\", \"\"\n",
    "\n",
    "    # Intentar transcribir automáticamente el texto para indexar (si hay imagen válida)\n",
    "    if current_image:\n",
    "        print(\"Realizando transcripción inicial de la imagen para el RAG...\")\n",
    "        indexed_text_content = perform_ocr_with_paligemma(current_image)\n",
    "        if len(indexed_text_content) > 5000: # Limitar para no saturar prompts\n",
    "            indexed_text_content = indexed_text_content[:5000] + \"...\"\n",
    "        print(\"Transcripción inicial completada.\")\n",
    "        return status_message, current_image, indexed_text_content, \"\"\n",
    "    else:\n",
    "        return status_message, None, \"\", \"\"\n",
    "\n",
    "\n",
    "def rag_query(query):\n",
    "    \"\"\"\n",
    "    Responde a preguntas sobre la imagen, utilizando el texto indexado si es relevante.\n",
    "    \"\"\"\n",
    "    global current_image\n",
    "    global indexed_text_content\n",
    "\n",
    "    if current_image is None:\n",
    "        return \"Por favor, primero sube una imagen o PDF.\", \"\"\n",
    "\n",
    "    if not query:\n",
    "        return \"Por favor, ingresa una pregunta.\"\n",
    "\n",
    "    # Combinar la pregunta del usuario con el texto extraído (indexado) como contexto\n",
    "    # Esto simula un RAG simple: el \"recuperador\" es el OCR, y el \"generador\" es PaliGemma.\n",
    "    context_prompt = \"\"\n",
    "    if indexed_text_content:\n",
    "        context_prompt = f\"Basado en el siguiente texto extraído de la imagen: '{indexed_text_content}' y la imagen, responde a la pregunta.\"\n",
    "\n",
    "    full_prompt = f\"{context_prompt}\\n\\nPregunta: {query}\\n\\nRespuesta:\"\n",
    "\n",
    "    print(f\"Prompt enviado a PaliGemma: {full_prompt[:200]}...\") # Para depuración\n",
    "\n",
    "    response = generate_paligemma_response(current_image, full_prompt, max_new_tokens=300)\n",
    "    return response, indexed_text_content # Retorna la respuesta y el texto indexado\n",
    "\n",
    "\n",
    "def perform_translation_mode(text_to_translate, source_lang, target_lang):\n",
    "    \"\"\"Función para el modo traductor.\"\"\"\n",
    "    return translate_text(text_to_translate, source_lang, target_lang)\n",
    "\n",
    "# --- Interfaz de Gradio ---\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Asistente de Estudio Multimodal con PaliGemma y Traducción\")\n",
    "    gr.Markdown(\"Sube una imagen o PDF (se procesará la primera página) para hacer preguntas, transcribir o traducir su contenido.\")\n",
    "\n",
    "    with gr.Tab(\"Asistente Visual (Preguntas y OCR)\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                file_input = gr.File(label=\"Sube tu material (Imagen/PDF)\")\n",
    "                image_display = gr.Image(label=\"Imagen del Material\", type=\"pil\", show_label=True)\n",
    "                status_output = gr.Textbox(label=\"Estado del Archivo\", interactive=False)\n",
    "                indexed_text_display = gr.Textbox(label=\"Texto Transcrito (OCR) de la Imagen (Para Referencia)\", interactive=False, lines=5)\n",
    "                load_button = gr.Button(\"Cargar y Analizar Archivo\")\n",
    "\n",
    "            with gr.Column():\n",
    "                question_input = gr.Textbox(label=\"Haz una pregunta sobre el material\", placeholder=\"Ej: ¿Qué se explica en este diagrama? o ¿Cuál es la fórmula aquí?\")\n",
    "                rag_output = gr.Textbox(label=\"Respuesta del Asistente\", interactive=False, lines=5)\n",
    "                query_button = gr.Button(\"Enviar Pregunta\")\n",
    "                transcribe_button = gr.Button(\"Transcribir Texto (OCR)\")\n",
    "                explanation_button = gr.Button(\"Explicar Contenido Visual\")\n",
    "                clear_button = gr.Button(\"Limpiar Todo\")\n",
    "\n",
    "\n",
    "        load_button.click(\n",
    "            fn=index_data,\n",
    "            inputs=file_input,\n",
    "            outputs=[status_output, image_display, indexed_text_display]\n",
    "        )\n",
    "        query_button.click(\n",
    "            fn=rag_query,\n",
    "            inputs=[question_input],\n",
    "            outputs=[rag_output, indexed_text_display]\n",
    "        )\n",
    "        transcribe_button.click(\n",
    "            fn=lambda img: perform_ocr_with_paligemma(img) if img else \"Por favor, sube una imagen primero.\",\n",
    "            inputs=image_display,\n",
    "            outputs=rag_output # Muestra la transcripción en la caja de respuesta\n",
    "        )\n",
    "        explanation_button.click(\n",
    "            fn=lambda img: explain_image_content(img) if img else \"Por favor, sube una imagen primero.\",\n",
    "            inputs=image_display,\n",
    "            outputs=rag_output # Muestra la explicación en la caja de respuesta\n",
    "        )\n",
    "        clear_button.click(\n",
    "            fn=lambda: (\"\", None, \"\", \"\", \"\"),\n",
    "            inputs=[],\n",
    "            outputs=[file_input, image_display, status_output, indexed_text_display, rag_output]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Modo Traductor\"):\n",
    "        gr.Markdown(\"Introduce texto y selecciona los idiomas para traducir.\")\n",
    "        with gr.Row():\n",
    "            translation_input = gr.Textbox(label=\"Texto a Traducir\", lines=5)\n",
    "            with gr.Column():\n",
    "                source_lang_dropdown = gr.Dropdown([\"en\", \"es\"], label=\"Idioma Origen\", value=\"en\")\n",
    "                target_lang_dropdown = gr.Dropdown([\"en\", \"es\"], label=\"Idioma Destino\", value=\"es\")\n",
    "                translate_button = gr.Button(\"Traducir\")\n",
    "            translation_output = gr.Textbox(label=\"Texto Traducido\", interactive=False, lines=5)\n",
    "\n",
    "        translate_button.click(\n",
    "            fn=perform_translation_mode,\n",
    "            inputs=[translation_input, source_lang_dropdown, target_lang_dropdown],\n",
    "            outputs=translation_output\n",
    "        )\n",
    "\n",
    "demo.launch(debug=True, share=True) # share=True para un link público en Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
